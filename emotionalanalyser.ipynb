{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade transformers accelerate\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset, Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import transformers\n",
        "print(transformers.__version__)\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "\n",
        "ds = load_dataset(\"go_emotions\", \"simplified\")\n",
        "label_names = ds[\"train\"].features[\"labels\"].feature.names\n",
        "num_labels = len(label_names)\n",
        "\n",
        "\n",
        "train_data = ds[\"train\"].to_pandas()\n",
        "\n",
        "\n",
        "def create_multi_hot_labels(labels_list, num_labels):\n",
        "    vec = [0.0] * num_labels\n",
        "    for i in labels_list:\n",
        "        vec[i] = 1.0\n",
        "    return vec\n",
        "\n",
        "\n",
        "train_data['multi_hot_labels'] = train_data['labels'].apply(lambda x: create_multi_hot_labels(x, num_labels))\n",
        "\n",
        "for i, emotion in enumerate(label_names):\n",
        "    train_data[emotion] = train_data['labels'].apply(lambda x: 1 if i in x else 0)\n",
        "\n",
        "label_cols = label_names\n",
        "emotion_counts = train_data[label_cols].sum().sort_values()\n",
        "\n",
        "print(\"ðŸ“Š Original Emotion Counts:\")\n",
        "print(emotion_counts)\n",
        "\n",
        "\n",
        "rare_emotions = emotion_counts.head(10).index.tolist()\n",
        "print(\"ðŸ” Rare emotions:\", rare_emotions)\n",
        "\n",
        "target_count = emotion_counts.median()\n",
        "print(f\"ðŸŽ¯ Target count: {target_count}\")\n",
        "\n",
        "\n",
        "augmented_df = train_data.copy()\n",
        "\n",
        "# Go through each rare emotion and duplicate rows containing that emotion\n",
        "for emotion in rare_emotions:\n",
        "    current_count = emotion_counts[emotion]\n",
        "    multiplier = math.floor(target_count / current_count) - 1\n",
        "\n",
        "\n",
        "    emotion_rows = train_data[train_data[emotion] == 1].copy()\n",
        "\n",
        "\n",
        "    for _ in range(multiplier):\n",
        "        augmented_df = pd.concat([augmented_df, emotion_rows], ignore_index=True)\n",
        "\n",
        "    print(f\"âœ… Duplicated rows with {emotion} x{multiplier} â†’ Added {len(emotion_rows) * multiplier} rows\")\n",
        "\n",
        "# Shuffle dataset\n",
        "augmented_df = augmented_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Check new counts\n",
        "new_counts = augmented_df[label_cols].sum().sort_values()\n",
        "print(\"\\nðŸ“ˆ New Emotion Counts:\")\n",
        "print(new_counts)\n",
        "\n",
        "print(f\"\\nðŸ“Š Dataset size: {len(train_data)} â†’ {len(augmented_df)} (+{len(augmented_df) - len(train_data)} rows)\")\n",
        "\n",
        "# Keep only necessary columns and convert multi_hot_labels back to the format expected by training\n",
        "augmented_train_data = augmented_df[['text', 'multi_hot_labels']].copy()\n",
        "augmented_train_data = augmented_train_data.rename(columns={'multi_hot_labels': 'labels'})\n",
        "\n",
        "augmented_train_ds = Dataset.from_pandas(augmented_train_data)\n",
        "\n",
        "# 80/10/10 SPLIT\n",
        "split_ds = augmented_train_ds.train_test_split(test_size=0.2, seed=42)\n",
        "train_ds = split_ds[\"train\"]\n",
        "temp_ds = split_ds[\"test\"]\n",
        "\n",
        "val_test_split = temp_ds.train_test_split(test_size=0.5, seed=42)\n",
        "val_ds = val_test_split[\"train\"]\n",
        "test_ds = val_test_split[\"test\"]\n",
        "\n",
        "print(f\"\\nðŸ“Š Dataset splits:\")\n",
        "print(f\"Train: {len(train_ds)} ({len(train_ds)/len(augmented_train_ds)*100:.1f}%)\")\n",
        "print(f\"Val:   {len(val_ds)} ({len(val_ds)/len(augmented_train_ds)*100:.1f}%)\")\n",
        "print(f\"Test:  {len(test_ds)} ({len(test_ds)/len(augmented_train_ds)*100:.1f}%)\")\n",
        "\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "train_ds = train_ds.map(tokenize, batched=True)\n",
        "val_ds = val_ds.map(tokenize, batched=True)\n",
        "test_ds = test_ds.map(tokenize, batched=True)\n",
        "\n",
        "\n",
        "columns = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "train_ds.set_format(type=\"torch\", columns=columns)\n",
        "val_ds.set_format(type=\"torch\", columns=columns)\n",
        "test_ds.set_format(type=\"torch\", columns=columns)\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.tensor(logits))\n",
        "    y_pred = (probs > 0.5).int().numpy()\n",
        "    y_true = labels\n",
        "    acc = (y_pred == y_true).mean()\n",
        "    f1_micro = f1_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
        "    f1_macro = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"f1_micro\": f1_micro,\n",
        "        \"f1_macro\": f1_macro,\n",
        "    }"
      ],
      "metadata": {
        "id": "1HMM52BeoPxr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b5b4e48884ef429095f44b2182f48537",
            "5467d4cdcd3f42d69b83af977eb34827",
            "bba61ccf930b4ff9b6d34e9c4dde3ab8",
            "943a128956354a7dad3e853b0ab0b464",
            "c84a30588621497fa65156f550b49a47",
            "3e358b85fdc044a5bb553f6c9301d830",
            "bd19f59b9a754415a0cb92aacc6edbe7",
            "224129bccc6b41f09d85b6cb6df497a1",
            "5fb16e5981874fcfbc939f5cc6cae03d",
            "11b4a76df140457297df879f60b85aac",
            "954f9e6d35ff4613b38a8587c7b6ea71",
            "45f1bcfa567441e3aec6fb4655fc59f4",
            "6e36a67c2c8f4c689b771676c886c0ff",
            "90755cd3f8a940f88dcf23619b7776d6",
            "cdfdfb0ce3094bab851ab291451e4e64",
            "ad6b2433807f4707aa1cfd19eefceb5f",
            "6e4eec09f86f40d8bcf3d6af87be2f16",
            "6a61557dd7b7438e90d214f399fad319",
            "96b66a3931484260b382bbee657dac4a",
            "ef0e5e5e35804dec938303ff1d430f9a",
            "8600e5a0750a40eb968f0f094e8af194",
            "0fadffa9fc8743e8b989cf38222b034b",
            "2a0bd3d48aba4e1aa83b0913f1151a09",
            "bae4106463514bf5be0ebdad3e72dd9c",
            "d88e541f7c01419cb085deb6e700ac6e",
            "596d171efa9547a5afb7b6640b1cfa16",
            "53db941772034140b4f1eec147f2fef7",
            "31ab68a7c0d34398a9715a1f1f33d9f7",
            "d293d7c5e07d4726aec6aecde328314f",
            "e04c450482d448ffa28db917685140fb",
            "ca2ee7c324db46a7938f23d4cd34822c",
            "4278502cf7754acda8af6a49b73d2280",
            "0d220d5d816a41dab41d27e8315900cf",
            "bad69d9569b6495b8b7d53b01abb4a1f",
            "71cf113cdb094d02bc800ba53c9a6fdf",
            "3f9def829ec34acbb8e64f566d5d6be1",
            "c9040b59a53c4342a3bc419910264b8e",
            "718b8f51f0524ceb9abaf39f53ca3514",
            "cce92f06b4ef4d76b002867a07bb2feb",
            "b7ca85a00f1b40e5954c3ecadd1b43a3",
            "8465737878084244ad4e9b267edcdc5c",
            "b08ff1d400c94374be3f69f3cd3dc7d2",
            "5488c452b6da416cb18459211acd72f7",
            "e3efc4630a574fb3861b68d793938db3",
            "7de61a9186e74b21b91d918b087dec60",
            "cb919996fbb248c4975fc015c41af4a5",
            "5fadf8f3aa944a858cbcb02f287af0f7",
            "7e129d63dfac4abfb6309072634f7a99",
            "a3e86ef1de024e5588919fe4952a4a79",
            "17826143ed2c44f49b13b32de50948ba",
            "58fe198535c54e51aa7b2728cd414d21",
            "4a474924503b47708da284e07be98dfc",
            "addf05b6c0664c698968af34856267b4",
            "72e3d20d4abf4046bae21f365881dba2",
            "d32349d02ccf40c6bfb09e2c1b04df38",
            "e95431b540c44c79b31dff142afdc8bb",
            "a777a0a2e0214e778cd226571145d457",
            "4e4e50a1910b48d784a1a33afc2c5196",
            "1e87da992e814b9f94a6e2e9265c8e94",
            "6c6b08df28ec434bba18ee773c264468",
            "53bf770d51594f219596167bf03549a8",
            "31e24cb57576423fba213cf54984346d",
            "507909f5c66f4440b0036bb42db1d914",
            "906ab5f8e50947efb4b286fdc0ecef41",
            "69b98ea0769e4152a5f780d137165936",
            "34c7cd4468a44b41a70e9301df584dd1",
            "4b092fae9b3c49a49432d19f23c2904c",
            "b64b8619c49b4211a98915ca1ebae917",
            "9610e6ef7e6f404eae029b45de58ddca",
            "b625eba1e95b4314af43c17d97e426f4",
            "f5b17f8d517548d0b205e996b8cecd62",
            "36c3ac96a6594a1fbfef871f328eb6e6",
            "7bebf8d051ab4a318cc525f5eeebfed3",
            "b3d43c306fc945618ef59092085c4f58",
            "6847c22f291b4b46a97ce8dbadaa413c",
            "a9b8ea4356c14a598a0319677cb4f8a7",
            "a7f84215270d4deeb3f616d630620426",
            "fbfc181988384d46b3d88fe5488e3643",
            "ff10c9cf9a6a49f581b73c8baf2b5c38",
            "1cace3af67884292ba66109570aae4e6",
            "29f37cb7a21245809cba85b1895c6f90",
            "3fd5025bd42f40f3979bdd48b9f6c6b7",
            "e4bd21c6db3f4cda8799758587924ba2",
            "2836e22560a442fc941e81fd5b0e91b3",
            "2a04e43844694ab5a0feb7555c8aac6f",
            "e7afd572e9354d17bb9a35c4588b8baa",
            "94b4e42078604a9e9c9a3d011c96c2fa",
            "ef8667c774e7499f8869d28d54b1cc96",
            "75175d7bda8544f481b0ac9c1756d4ea",
            "4026a9d47a0942e5b783ab8fcd42ca6b",
            "976b79e850cb489e8cd0a3f81d5044a6",
            "03989f63a0f543ea904df2649bd21d68",
            "e577eb6d040746dfbf2d86730c45ef83",
            "66a2da277b9446cba535302bd3591479",
            "cca98ec1b5e64d718d4e2de2f2a0910f",
            "0cac49b0805744c1bf7fbc643f1a87f7",
            "8ee63b63741d4b539c93891f863cf3dc",
            "1c692800d80346e08b5b9f53f3b6bbb0",
            "0033995e03e541d5ab7577c49b385324",
            "32316da5cfb847ca8f702a1fa4348a28",
            "71d9a13760fc44de92fefb9f951ae4ca",
            "7dac6dd34e5248ec98762c72444492e0",
            "ca08e3abbce34cbc9d415059fe024670",
            "1c018cd94f514293ba5eeed6391f3a82",
            "b9e09102877e4983badc64c52ddb5416",
            "a09016bb14b24eed8c4233df45e28b3d",
            "ff8dfcbe821248a7b5cac96e9196f47b",
            "0e36d9c266c54c33b504d476e0820fec",
            "3457eb64691d48788fd7dad1943b0c36",
            "f496050602594b6eaff0cc9836d7da90",
            "b6e0a749bde14e72b32146486f3cd979",
            "cb2ea552172a4ad9b6bb3eeeeaf937db",
            "a5b32a84ae114946bba5fe4c980fff31",
            "ccee84aa4c5c46629187f731c9e4b0d4",
            "6b46ba6cc6fb4bd09978fbc608b07dd5",
            "2287ccf7ec0444ffa27a08092ae853b0",
            "aadf20f81362413c88e3fb91b7ad9d73",
            "3a3ca7a264564bb590e9c334987b8367",
            "7a3e43f2273e411ca7e34be9177208b8",
            "e072f5d144044ca8a7b6e743b9836f14",
            "be8413db751d43c59611478e15dfe086",
            "2e898d05efa5475c9c3b537dadf0b626",
            "60c44b8c840e490ab0f8219810e7952e",
            "e0612dc1194f48a6928d3397a388099e",
            "ad113dbb475d46a0808996296af2d921",
            "4546ac3a59774c7da49ec076c2e707d6",
            "ab1d1dc8432748808204313b35099a9e",
            "624b6a36388b43b6958c02238add06f3",
            "1be5825fd7ee4779b0af242aab08f96e",
            "3dbdc95a0354443b8f2136affef59307",
            "5a587278a730484cb2970de6c763cf81",
            "919d959728394ba38b2c36f709491c3e",
            "30ea1db91ff34c5caec06a70ac8b2698",
            "db2fb0647b7a4619a462e38c9f6bf2d4",
            "0707a33a8cd24d6d9cee7104d82ba864",
            "f051dc09dbcb4fcca1cf22380702476a",
            "a30ed190d32243af95c1998d8bce78c4",
            "dfde1873ca8a4d668026db160a296fc5",
            "ba744bc1e4bd4c3cbd1d3d185745bb97",
            "24a7dbd4312d4718ab30ac3cc4ec9869",
            "1639c18d41234cc3b6778e04d20a31eb",
            "e6fd533026a243a9b845467be0bccbb5",
            "df916fc79ebf466eab9f47ec8c2fe697",
            "b8a45fdc938c4290a924ac27338e671a",
            "b2fc45b607814ab9b0c1a7680c0bd895",
            "3059d5161e2a4ed69cd87c79926e1116",
            "2b3fd1c860274a3498cec8eb2f7fb9a7",
            "5464cf2590324560af01ccbcf5ad697f",
            "387dd0c785794ab8aed15c311f823c8e",
            "ffad5dfd9b524fc5b365371d95e20a22",
            "2642f15df2b14f3a8a3f195097b2f8a8",
            "990b348664974e8487e284b703ab9c34",
            "cf0b7968d6584546a60b16ef4554b5cb",
            "17d15c523aba460e9c2fdbeb1647261f",
            "51a464485b0d46c689ef33e02d1a1aa3",
            "a8421469882d4bd2a4d5598d69e119d0",
            "9e3147f396ef450699eb27514b23a107",
            "a97c2684e9d241a3bd1ef203ba398477",
            "32ff170c9681485ca5cca9027635a752",
            "1a985c5281b9440cad9ccb019b4ffffc",
            "f0c9d53715ec4e539e9423d090a6e8c5",
            "cf2718de4df94cd3911ea462fb41b31a",
            "d7214d4e6e7d4b0bb1bf4ab8185d622f",
            "128e2c6c0f8f457e99442527d583931b",
            "971c95daa26f41c396f3a672b98abc68"
          ]
        },
        "outputId": "73ceb14d-742a-48af-952d-ed9302ece1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.55.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5b4e48884ef429095f44b2182f48537"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "simplified/train-00000-of-00001.parquet:   0%|          | 0.00/2.77M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45f1bcfa567441e3aec6fb4655fc59f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "simplified/validation-00000-of-00001.par(â€¦):   0%|          | 0.00/350k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a0bd3d48aba4e1aa83b0913f1151a09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "simplified/test-00000-of-00001.parquet:   0%|          | 0.00/347k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bad69d9569b6495b8b7d53b01abb4a1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/43410 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7de61a9186e74b21b91d918b087dec60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/5426 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e95431b540c44c79b31dff142afdc8bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/5427 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b092fae9b3c49a49432d19f23c2904c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Original Emotion Counts:\n",
            "grief                77\n",
            "pride               111\n",
            "relief              153\n",
            "nervousness         164\n",
            "embarrassment       303\n",
            "remorse             545\n",
            "fear                596\n",
            "desire              641\n",
            "disgust             793\n",
            "excitement          853\n",
            "surprise           1060\n",
            "caring             1087\n",
            "realization        1110\n",
            "disappointment     1269\n",
            "sadness            1326\n",
            "confusion          1368\n",
            "joy                1452\n",
            "anger              1567\n",
            "optimism           1581\n",
            "disapproval        2022\n",
            "love               2086\n",
            "curiosity          2191\n",
            "amusement          2328\n",
            "annoyance          2470\n",
            "gratitude          2662\n",
            "approval           2939\n",
            "admiration         4130\n",
            "neutral           14219\n",
            "dtype: int64\n",
            "ðŸ” Rare emotions: ['grief', 'pride', 'relief', 'nervousness', 'embarrassment', 'remorse', 'fear', 'desire', 'disgust', 'excitement']\n",
            "ðŸŽ¯ Target count: 1297.5\n",
            "âœ… Duplicated rows with grief x15 â†’ Added 1155 rows\n",
            "âœ… Duplicated rows with pride x10 â†’ Added 1110 rows\n",
            "âœ… Duplicated rows with relief x7 â†’ Added 1071 rows\n",
            "âœ… Duplicated rows with nervousness x6 â†’ Added 984 rows\n",
            "âœ… Duplicated rows with embarrassment x3 â†’ Added 909 rows\n",
            "âœ… Duplicated rows with remorse x1 â†’ Added 545 rows\n",
            "âœ… Duplicated rows with fear x1 â†’ Added 596 rows\n",
            "âœ… Duplicated rows with desire x1 â†’ Added 641 rows\n",
            "âœ… Duplicated rows with disgust x1 â†’ Added 793 rows\n",
            "âœ… Duplicated rows with excitement x1 â†’ Added 853 rows\n",
            "\n",
            "ðŸ“ˆ New Emotion Counts:\n",
            "remorse            1162\n",
            "surprise           1166\n",
            "realization        1209\n",
            "nervousness        1209\n",
            "pride              1227\n",
            "relief             1234\n",
            "caring             1239\n",
            "grief              1245\n",
            "embarrassment      1261\n",
            "desire             1313\n",
            "confusion          1415\n",
            "fear               1422\n",
            "disappointment     1458\n",
            "disgust            1644\n",
            "anger              1686\n",
            "joy                1692\n",
            "excitement         1773\n",
            "sadness            1844\n",
            "optimism           1860\n",
            "disapproval        2138\n",
            "love               2181\n",
            "curiosity          2314\n",
            "amusement          2440\n",
            "annoyance          2696\n",
            "gratitude          2889\n",
            "approval           3135\n",
            "admiration         4559\n",
            "neutral           14550\n",
            "dtype: int64\n",
            "\n",
            "ðŸ“Š Dataset size: 43410 â†’ 52067 (+8657 rows)\n",
            "\n",
            "ðŸ“Š Dataset splits:\n",
            "Train: 41653 (80.0%)\n",
            "Val:   5207 (10.0%)\n",
            "Test:  5207 (10.0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbfc181988384d46b3d88fe5488e3643"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75175d7bda8544f481b0ac9c1756d4ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32316da5cfb847ca8f702a1fa4348a28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6e0a749bde14e72b32146486f3cd979"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/41653 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e898d05efa5475c9c3b537dadf0b626"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5207 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30ea1db91ff34c5caec06a70ac8b2698"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5207 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8a45fdc938c4290a924ac27338e671a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51a464485b0d46c689ef33e02d1a1aa3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/fine_tuned_model\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1, #MAKE IT 3\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='/content/logs',\n",
        "    logging_steps=100,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    save_total_limit=1,\n",
        "    do_eval=True,\n",
        "    do_train=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nðŸš€ Starting training...\")\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "print(\"\\nðŸ“Š Validation Results:\")\n",
        "val_results = trainer.evaluate(eval_dataset=val_ds)\n",
        "print(val_results)\n",
        "\n",
        "\n",
        "print(\"\\nðŸŽ¯ Final Test Results:\")\n",
        "test_results = trainer.evaluate(eval_dataset=test_ds)\n",
        "print(test_results)\n",
        "\n",
        "\n",
        "trainer.save_model()\n",
        "print(\"\\nðŸ’¾ Model saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OhxxR08vq-J9",
        "outputId": "38e3ce08-5287-49c2-de8b-4fa3b811f95d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4194524859.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸš€ Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2604' max='2604' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2604/2604 15:59, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.126300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.115300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.098600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.094700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.088600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.107600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.103900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.099900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.099600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.095700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.097400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.093900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.094900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.093200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.089400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.089500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.089500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.090300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.088400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.089500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.088200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.087400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.087300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.085600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.085100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Validation Results:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='652' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [326/326 01:15]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.08287400752305984, 'eval_accuracy': 0.9713092265905786, 'eval_f1_micro': 0.6006682577565633, 'eval_f1_macro': 0.5508386244220841, 'eval_runtime': 38.5754, 'eval_samples_per_second': 134.982, 'eval_steps_per_second': 8.451, 'epoch': 1.0}\n",
            "\n",
            "ðŸŽ¯ Final Test Results:\n",
            "{'eval_loss': 0.08137676864862442, 'eval_accuracy': 0.9716521715273396, 'eval_f1_micro': 0.6015617468427649, 'eval_f1_macro': 0.5475534538039282, 'eval_runtime': 37.4865, 'eval_samples_per_second': 138.903, 'eval_steps_per_second': 8.696, 'epoch': 1.0}\n",
            "\n",
            "ðŸ’¾ Model saved!\n"
          ]
        }
      ]
    }
  ]
}